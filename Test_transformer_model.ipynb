{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvCufeCW9VUe",
        "outputId": "40f9414f-f201-4f3c-d291-fb2472ff3865"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/485.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets\n",
        "!pip install -q sacrebleu\n",
        "!pip install -q import-ipynb\n",
        "!pip install -q tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXQEsCu6NV1A",
        "outputId": "90745101-8c4e-45ed-cac2-ea0100585bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ofoQhpSjNxZ9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.utils.tensorboard.writer import SummaryWriter\n",
        "import torch.optim as optim\n",
        "import warnings\n",
        "from sacrebleu import corpus_bleu\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from pathlib import Path\n",
        "from typing import Any\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7qArp68RJUQs"
      },
      "outputs": [],
      "source": [
        "def get_config():\n",
        "    return {\n",
        "        \"batch_size\": 32,\n",
        "        \"num_epochs\": 10,\n",
        "        \"lr\": 2e-4,\n",
        "        \"seq_len\": 570,\n",
        "        \"d_model\": 512,\n",
        "        \"datasource\": 'Helsinki-NLP/news_commentary',\n",
        "        \"lang_src\": \"en\",\n",
        "        \"lang_tgt\": \"ru\",\n",
        "        \"model_folder\": \"/content/drive/MyDrive/Colab Notebooks/Transformer\",  # Путь в Colab\n",
        "        \"model_basename\": \"transformer_translate_model\",\n",
        "        \"preload\": None,\n",
        "        \"tokenizer_file\": \"tokenizer_{0}.json\",\n",
        "        \"experimental_name\": \"runs/transformer_translate_model\"\n",
        "    }\n",
        "\n",
        "def get_weights_file_path(config, epoch: str):\n",
        "    model_folder = config['model_folder']\n",
        "    model_basename = config['model_basename']\n",
        "    model_filename = f\"{model_basename}{epoch}.pt\"\n",
        "    return str(Path('.') / model_folder / model_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Kw9m10zFH_z4"
      },
      "outputs": [],
      "source": [
        "class InputEmbeddings(nn.Module):\n",
        "    # Инициализация слоя для встраивания входных данных\n",
        "    def __init__(self, d_model: int, vocab_size: int):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model  # Размерность модели (выходной размер embedding)\n",
        "        self.vocab_size = vocab_size  # Размер словаря\n",
        "        # Слой embedding, который преобразует индексы слов в векторы размером d_model\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Получаем embeddings и умножаем на корень из размерности модели для нормализации\n",
        "        return self.embedding(x) * math.sqrt(self.d_model)\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    # Класс для добавления позиционного кодирования к входным данным\n",
        "    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model  # Размерность модели\n",
        "        self.seq_len = seq_len  # Длина последовательности\n",
        "        self.dropout = nn.Dropout(dropout)  # Слой dropout для регуляризации\n",
        "        pe = torch.zeros(seq_len, d_model)  # Инициализация матрицы позиционного кодирования\n",
        "        position = torch.arange(0, seq_len, dtype=torch.float32).unsqueeze(1)  # Позиции в последовательности\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))  # Нормировка\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)  # Синус для четных индексов\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)  # Косинус для нечетных индексов\n",
        "        pe = pe.unsqueeze(0)  # Добавляем размерность для батча\n",
        "        self.register_buffer('pe', pe)  # Регистрация буфера, чтобы не учитывать это при вычислении градиентов\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Добавляем позиционное кодирование к входу\n",
        "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)\n",
        "        return self.dropout(x)  # Применяем dropout\n",
        "\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "    # Слой нормализации\n",
        "    def __init__(self, eps: float = 1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps  # Эпсилон для предотвращения деления на ноль\n",
        "        self.alpha = nn.Parameter(torch.ones(1))  # Параметр масштабирования\n",
        "        self.bias = nn.Parameter(torch.zeros(1))  # Параметр сдвига\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Нормализация по последней оси (для каждого элемента последовательности)\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.alpha * (x - mean) / (std + self.eps) + self.bias\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    # Простой полносвязный слой с активацией ReLU и dropout\n",
        "    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)  # Первый линейный слой\n",
        "        self.dropout = nn.Dropout(dropout)  # Dropout\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)  # Второй линейный слой\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(torch.relu(self.linear1(x)))  # Применяем ReLU и dropout\n",
        "        x = self.linear2(x)  # Пропускаем через второй линейный слой\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadAttentionBlock(nn.Module):\n",
        "    # Модуль многоголовой внимательности\n",
        "    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model  # Размерность модели\n",
        "        self.h = h  # Количество голов в механизме внимания\n",
        "        assert d_model % h == 0, \"d_model must be divisible by h\"  # Проверка, что размерность делится на количество голов\n",
        "        self.d_k = d_model // h  # Размерность каждого подпространства внимания\n",
        "        self.w_q = nn.Linear(d_model, d_model)  # Линейный слой для получения queries\n",
        "        self.w_k = nn.Linear(d_model, d_model)  # Линейный слой для получения keys\n",
        "        self.w_v = nn.Linear(d_model, d_model)  # Линейный слой для получения values\n",
        "        self.w_o = nn.Linear(d_model, d_model)  # Линейный слой для проекции выходных данных\n",
        "        self.dropout = nn.Dropout(dropout)  # Dropout\n",
        "\n",
        "    @staticmethod\n",
        "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
        "        # Вычисление внимания с маской\n",
        "        d_k = query.shape[-1]\n",
        "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)  # Скалярное произведение и нормализация\n",
        "        if mask is not None:\n",
        "            attention_scores = attention_scores.masked_fill(mask == 0, -1e9)  # Применяем маску\n",
        "        attention_scores = attention_scores.softmax(dim=-1)  # Softmax для вычисления вероятностей\n",
        "        if dropout is not None:\n",
        "            attention_scores = dropout(attention_scores)  # Применяем dropout\n",
        "        return (attention_scores @ value), attention_scores  # Возвращаем результаты внимания\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        # Применение внимания с несколькими головами\n",
        "        query = self.w_q(q)\n",
        "        key = self.w_k(k)\n",
        "        value = self.w_v(v)\n",
        "        # Перемещаем размерности для многоголового внимания\n",
        "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        # Вычисляем внимание\n",
        "        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n",
        "        # Возвращаем проекцию через линейный слой\n",
        "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
        "        return self.w_o(x)\n",
        "\n",
        "\n",
        "class ResidualConnection(nn.Module):\n",
        "    # Остаточная связь с нормализацией и dropout\n",
        "    def __init__(self, dropout: float):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)  # Dropout\n",
        "        self.norm = LayerNormalization()  # Нормализация\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        # Возвращаем сумму входных данных и выходных данных с субслоем, применяя нормализацию и dropout\n",
        "        return x + self.dropout(sublayer(self.norm(x)))\n",
        "\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    # Блок энкодера, включающий внимание и feed-forward слой\n",
        "    def __init__(self, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForward, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.self_attention_block = self_attention_block  # Модуль самовнимания\n",
        "        self.feed_forward_block = feed_forward_block  # Модуль feed-forward\n",
        "        self.residual_connection = nn.ModuleList([ResidualConnection(dropout) for _ in range(2)])  # Остаточные связи\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        # Применяем остаточные связи и слои\n",
        "        x = self.residual_connection[0](x, lambda x: self.self_attention_block(x, x, x, src_mask))\n",
        "        x = self.residual_connection[1](x, self.feed_forward_block)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    # Модуль энкодера, который состоит из нескольких слоев энкодеров\n",
        "    def __init__(self, layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = layers  # Слои энкодера\n",
        "        self.norm = LayerNormalization()  # Нормализация\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # Проходим через все слои энкодера\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return self.norm(x)  # Возвращаем нормализованные данные\n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    # Блок декодера, включающий самовнимание, перекрестное внимание и feed-forward слой\n",
        "    def __init__(self, self_attention_block: MultiHeadAttentionBlock, cross_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForward, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.self_attention_block = self_attention_block  # Модуль самовнимания\n",
        "        self.cross_attention_block = cross_attention_block  # Модуль перекрестного внимания\n",
        "        self.feed_forward_block = feed_forward_block  # Модуль feed-forward\n",
        "        self.residual_connections = nn.ModuleList([ResidualConnection(dropout) for _ in range(3)])  # Остаточные связи\n",
        "\n",
        "    def forward(self, x, memory, tgt_mask, memory_mask):\n",
        "        # Применяем остаточные связи и слои\n",
        "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\n",
        "        x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x, memory, memory, memory_mask))\n",
        "        x = self.residual_connections[2](x, self.feed_forward_block)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    # Модуль декодера, состоящий из нескольких слоев декодеров\n",
        "    def __init__(self, layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = layers  # Слои декодера\n",
        "        self.norm = LayerNormalization()  # Нормализация\n",
        "\n",
        "    def forward(self, x, memory, tgt_mask, memory_mask):\n",
        "        # Проходим через все слои декодера\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, tgt_mask, memory_mask)\n",
        "        return self.norm(x)  # Возвращаем нормализованные данные\n",
        "\n",
        "class ProjectionLayer(nn.Module):\n",
        "    # Проекционный слой, который преобразует выходные данные в вероятности для каждого слова в словаре\n",
        "    def __init__(self, d_model: int, vocab_size: int) -> None:\n",
        "        super().__init__()\n",
        "        # Линейный слой, который преобразует вектор размерности d_model в вектор размерности vocab_size\n",
        "        self.proj = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Применяем softmax по последней оси (для каждого слова) для получения вероятностей\n",
        "        return torch.log_softmax(self.proj(x), dim=-1)\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    # Основной класс трансформера, который включает энкодер, декодер и проекционный слой\n",
        "    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings,\n",
        "                 tgt_embed: InputEmbeddings, src_pos: PositionalEncoding, tgt_pos: PositionalEncoding,\n",
        "                 projection_layer: ProjectionLayer):\n",
        "        super().__init__()\n",
        "        # Инициализируем все компоненты трансформера\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.src_pos = src_pos\n",
        "        self.tgt_pos = tgt_pos\n",
        "        self.projection_layer = projection_layer\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        # Кодируем входную последовательность (источник)\n",
        "        src = self.src_embed(src)  # Применяем embedding для исходных данных\n",
        "        src = self.src_pos(src)  # Добавляем позиционное кодирование\n",
        "        return self.encoder(src, src_mask)  # Пропускаем через энкодер\n",
        "\n",
        "    def decode(self, encoder_output, src_mask, tgt, tgt_mask):\n",
        "        # Декодируем цельную последовательность (цель)\n",
        "        tgt = self.tgt_embed(tgt)  # Применяем embedding для целевых данных\n",
        "        tgt = self.tgt_pos(tgt)  # Добавляем позиционное кодирование\n",
        "        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)  # Пропускаем через декодер\n",
        "\n",
        "    def project(self, x):\n",
        "        # Применяем проекционный слой для перевода выходных данных в логарифмические вероятности\n",
        "        return self.projection_layer(x)\n",
        "\n",
        "\n",
        "def build_transformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int,\n",
        "                      tgt_seq_len: int, d_model: int = 512, N: int = 6, h: int = 8,\n",
        "                      dropout: float = 0.1, d_ff: int = 2048) -> Transformer:\n",
        "    # Строим трансформер с указанными параметрами\n",
        "    src_embed = InputEmbeddings(d_model, src_vocab_size)  # Слой для исходных эмбеддингов\n",
        "    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)  # Слой для целевых эмбеддингов\n",
        "    src_pos = PositionalEncoding(d_model, src_seq_len, dropout)  # Позиционное кодирование для исходных данных\n",
        "    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)  # Позиционное кодирование для целевых данных\n",
        "\n",
        "    # Создаем блоки энкодера\n",
        "    encoder_blocks = []\n",
        "    for _ in range(N):\n",
        "        encoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)  # Многоголовое внимание для энкодера\n",
        "        feed_forward_block = FeedForward(d_model, d_ff, dropout)  # Feed-forward блок\n",
        "        encoder_block = EncoderBlock(encoder_self_attention_block, feed_forward_block, dropout)  # Блок энкодера\n",
        "        encoder_blocks.append(encoder_block)\n",
        "\n",
        "    # Создаем блоки декодера\n",
        "    decoder_blocks = []\n",
        "    for _ in range(N):\n",
        "        decoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)  # Многоголовое внимание для декодера\n",
        "        decoder_cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)  # Перекрестное внимание\n",
        "        feed_forward_block = FeedForward(d_model, d_ff, dropout)  # Feed-forward блок\n",
        "        decoder_block = DecoderBlock(decoder_self_attention_block, decoder_cross_attention_block, feed_forward_block, dropout)  # Блок декодера\n",
        "        decoder_blocks.append(decoder_block)\n",
        "\n",
        "    # Создаем энкодер и декодер\n",
        "    encoder = Encoder(nn.ModuleList(encoder_blocks))\n",
        "    decoder = Decoder(nn.ModuleList(decoder_blocks))\n",
        "\n",
        "    # Создаем проекционный слой\n",
        "    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n",
        "\n",
        "    # Создаем трансформер\n",
        "    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n",
        "\n",
        "    # Инициализируем параметры трансформера\n",
        "    for p in transformer.parameters():\n",
        "        if p.dim() > 1:  # Инициализируем параметры с использованием Xavier инициализации для слоев с матрицами\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "    return transformer  # Возвращаем построенный трансформер\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "978NwTbFPs9O"
      },
      "outputs": [],
      "source": [
        "# Определение датасета для двуязычного текста\n",
        "class BiLanguageDataset(Dataset):\n",
        "    # Инициализация датасета, где будет храниться информация для пар исходных и целевых предложений\n",
        "    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len) -> None:\n",
        "        super().__init__()\n",
        "        # Сохраняем параметры, переданные при инициализации\n",
        "        self.ds = ds  # Датасет с парами исходных и целевых предложений\n",
        "        self.tokenizer_src = tokenizer_src  # Токенизатор для исходного языка\n",
        "        self.tokenizer_tgt = tokenizer_tgt  # Токенизатор для целевого языка\n",
        "        self.src_lang = src_lang  # Исходный язык\n",
        "        self.tgt_lang = tgt_lang  # Целевой язык\n",
        "        self.seq_len = seq_len  # Максимальная длина последовательности\n",
        "        # Определяем специальные токены для начала ([SOS]), конца ([EOS]) и заполнителя ([PAD])\n",
        "        self.sos_token = torch.tensor([tokenizer_src.token_to_id('[SOS]')], dtype=torch.int64)\n",
        "        self.eos_token = torch.tensor([tokenizer_src.token_to_id('[EOS]')], dtype=torch.int64)\n",
        "        self.pad_token = torch.tensor([tokenizer_src.token_to_id('[PAD]')], dtype=torch.int64)\n",
        "\n",
        "    # Возвращаем количество элементов в датасете\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    # Возвращаем один элемент из датасета (пар исходного и целевого текста)\n",
        "    def __getitem__(self, index: Any) -> Any:\n",
        "        # Получаем пару исходного и целевого текста\n",
        "        src_target_pair = self.ds[index]\n",
        "        src_text = src_target_pair['translation'][self.src_lang]  # Исходный текст\n",
        "        tgt_text = src_target_pair['translation'][self.tgt_lang]  # Целевой текст\n",
        "\n",
        "        # Токенизируем тексты в индексы токенов\n",
        "        enc_input_tokens = self.tokenizer_src.encode(src_text).ids  # Токены для исходного текста\n",
        "        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids  # Токены для целевого текста\n",
        "\n",
        "        # Вычисляем количество токенов для заполнения, чтобы привести длину до seq_len\n",
        "        enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2  # Минус 2 из-за SOS и EOS токенов\n",
        "        dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1  # Минус 1 для EOS\n",
        "\n",
        "        # Проверка на слишком длинные предложения\n",
        "        if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n",
        "            raise ValueError('Sentence is too long')  # Выбрасываем ошибку, если предложение слишком длинное\n",
        "\n",
        "        # Собираем вход для энкодера: добавляем SOS, токены текста, EOS и заполняем до seq_len\n",
        "        encoder_input = torch.cat(\n",
        "            [\n",
        "                self.sos_token,  # Начало исходной последовательности\n",
        "                torch.tensor(enc_input_tokens, dtype=torch.int64),  # Токены исходного текста\n",
        "                self.eos_token,  # Конец исходной последовательности\n",
        "                torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype=torch.int64)  # Заполнение до seq_len\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Собираем вход для декодера: добавляем SOS, токены целевого текста и заполняем до seq_len\n",
        "        decoder_input = torch.cat(\n",
        "            [\n",
        "                self.sos_token,  # Начало целевой последовательности\n",
        "                torch.tensor(dec_input_tokens, dtype=torch.int64),  # Токены целевого текста\n",
        "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64)  # Заполнение до seq_len\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Собираем метки (label) для декодера: токены целевого текста, EOS и заполняем до seq_len\n",
        "        label = torch.cat(\n",
        "            [\n",
        "                torch.tensor(dec_input_tokens, dtype=torch.int64),  # Токены целевого текста\n",
        "                self.eos_token,  # Конец последовательности\n",
        "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64)  # Заполнение до seq_len\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Проверка на правильность размеров всех последовательностей\n",
        "        assert encoder_input.size(0) == self.seq_len  # Должен быть одинаковый размер\n",
        "        assert decoder_input.size(0) == self.seq_len  # Должен быть одинаковый размер\n",
        "        assert label.size(0) == self.seq_len  # Должен быть одинаковый размер\n",
        "\n",
        "        # Возвращаем словарь с подготовленными данными\n",
        "        return {\n",
        "            'encoder_input': encoder_input,  # Вход для энкодера\n",
        "            'decoder_input': decoder_input,  # Вход для декодера\n",
        "            'encoder_mask': (encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(),  # Массив маски для энкодера\n",
        "            'decoder_mask': (decoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int() & causal_mask(decoder_input.size(0)),  # Массив маски для декодера\n",
        "            'label': label,  # Метки для декодера\n",
        "            'src_text': src_text,  # Исходный текст\n",
        "            'tgt_text': tgt_text  # Целевой текст\n",
        "        }\n",
        "\n",
        "# Функция для создания маски для декодера, где каждый токен может только \"видеть\" предыдущие\n",
        "def causal_mask(size):\n",
        "    # Создаем верхнюю треугольную матрицу (маску)\n",
        "    mask = torch.triu(torch.ones(1, size, size), diagonal=1).type(torch.int)\n",
        "    return mask == 0  # Все элементы выше главной диагонали становятся 0, остальные - 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "w_R75irKPu_k"
      },
      "outputs": [],
      "source": [
        "# Функция для получения модели\n",
        "def get_model(config, src_vocab_size, tgt_vocab_size):\n",
        "    # Строим модель с помощью конфигурации и размеров словаря исходного и целевого языков\n",
        "    model = build_transformer(src_vocab_size, tgt_vocab_size, config['seq_len'], config['seq_len'], d_model=config['d_model'])\n",
        "    return model\n",
        "\n",
        "# Функция для загрузки данных\n",
        "def get_ds(config):\n",
        "    # Загружаем датасет из источника данных, указанный в конфигурации\n",
        "    ds_raw = load_dataset(config['datasource'], f\"{config['lang_src']}-{config['lang_tgt']}\", split='train')\n",
        "\n",
        "    # Загружаем токенизаторы для исходного и целевого языка\n",
        "    tokenizer_src = Tokenizer.from_file(config['tokenizer_file'].format(config['lang_src']))\n",
        "    tokenizer_tgt = Tokenizer.from_file(config['tokenizer_file'].format(config['lang_tgt']))\n",
        "\n",
        "    # Разделяем датасет на обучающую и валидационную выборки (70% на обучение, 30% на валидацию)\n",
        "    train_ds_size = int(0.7 * len(ds_raw))  # 70% для обучения\n",
        "    val_ds_size = len(ds_raw) - train_ds_size  # 30% для валидации\n",
        "\n",
        "    # Разделение на обучающую и валидационную выборки\n",
        "    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])\n",
        "\n",
        "    # Создаем экземпляры датасетов для обучения и валидации\n",
        "    train_ds = BiLanguageDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "    val_ds = BiLanguageDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "\n",
        "    # Создаем загрузчики данных для обучения и валидации с батчами\n",
        "    train_dataloader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)  # shuffle=True для случайного перемешивания данных\n",
        "    val_dataloader = DataLoader(val_ds, batch_size=config['batch_size'], shuffle=False)  # shuffle=False для валидации\n",
        "\n",
        "    # Возвращаем даталоадеры и токенизаторы\n",
        "    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt\n",
        "\n",
        "# Функция для валидации модели\n",
        "def run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, seq_len, device, print_msg, global_step, writer, num_examples=2):\n",
        "    model.eval()  # Переводим модель в режим оценки (без обучения)\n",
        "    with torch.no_grad():  # Отключаем вычисления градиентов (память и скорость)\n",
        "        # Перебираем батчи из валидационного датасета\n",
        "        for batch in val_dataloader:\n",
        "            # Перемещаем данные в устройство (GPU или CPU)\n",
        "            encoder_input = batch['encoder_input'].to(device)\n",
        "            encoder_mask = batch['encoder_mask'].to(device)\n",
        "            decoder_input = batch['decoder_input'].to(device)\n",
        "            decoder_mask = batch['decoder_mask'].to(device)\n",
        "            label = batch['label'].to(device)\n",
        "\n",
        "            # Пропускаем вход через энкодер\n",
        "            output = model.encode(encoder_input, encoder_mask)\n",
        "            # Пропускаем через декодер\n",
        "            output = model.decode(output, encoder_mask, decoder_input, decoder_mask)\n",
        "            # Прогнозируем выход (логарифм вероятности для каждого токена)\n",
        "            output = model.project(output)\n",
        "\n",
        "            # Печатаем сообщение о текущем шаге валидации\n",
        "            print_msg(f\"Validation step {global_step}\")\n",
        "\n",
        "            # Прерываем цикл после первого батча (для примера)\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tvevEByRPx-3"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(model, src_text, tokenizer_src, tokenizer_tgt, seq_len, device):\n",
        "    # Переводим модель в режим оценки (без обучения)\n",
        "    model.eval()\n",
        "\n",
        "    # Отключаем вычисление градиентов для ускорения работы\n",
        "    with torch.no_grad():\n",
        "        # Токенизируем исходный текст с помощью токенизатора для исходного языка\n",
        "        src_tokens = tokenizer_src.encode(src_text).ids\n",
        "        # Преобразуем токены в тензор и добавляем дополнительную размерность для батча\n",
        "        src = torch.tensor(src_tokens, dtype=torch.int64).unsqueeze(0).to(device)\n",
        "\n",
        "        # Создаем маску для исходных данных (1 - если токен не [PAD], иначе 0)\n",
        "        src_mask = (src != tokenizer_src.token_to_id('[PAD]')).unsqueeze(0).unsqueeze(0).int().to(device)\n",
        "\n",
        "        # Пропускаем исходный текст через энкодер модели\n",
        "        encoder_output = model.encode(src, src_mask)\n",
        "\n",
        "        # Инициализируем токены для начала декодирования с символа [SOS]\n",
        "        tgt = torch.tensor([tokenizer_tgt.token_to_id('[SOS]')], dtype=torch.int64).unsqueeze(0).to(device)\n",
        "\n",
        "        # Начинаем генерировать целевой текст по очереди\n",
        "        for _ in range(seq_len):\n",
        "            # Создаем маску для декодера, которая предотвращает \"заглядывание\" в будущие токены\n",
        "            tgt_mask = causal_mask(tgt.size(1)).to(device)  # Функция causal_mask должна быть определена\n",
        "\n",
        "            # Пропускаем декодируемые данные через модель (декодер)\n",
        "            output = model.decode(encoder_output, src_mask, tgt, tgt_mask)\n",
        "\n",
        "            # Получаем логарифм вероятности для каждого токена\n",
        "            output = model.project(output)\n",
        "\n",
        "            # Выбираем токен с наибольшей вероятностью для следующего шага\n",
        "            next_token = output.argmax(dim=-1)[:, -1].item()\n",
        "\n",
        "            # Добавляем следующий токен к целевому вводу\n",
        "            tgt = torch.cat([tgt, torch.tensor([[next_token]], dtype=torch.int64).to(device)], dim=1)\n",
        "\n",
        "            # Прерываем цикл, если встретился токен окончания предложения [EOS]\n",
        "            if next_token == tokenizer_tgt.token_to_id('[EOS]'):\n",
        "                break\n",
        "\n",
        "        # Преобразуем сгенерированные токены в текст\n",
        "        translated_tokens = tgt.squeeze().tolist()\n",
        "        translated_text = tokenizer_tgt.decode(translated_tokens)\n",
        "\n",
        "        return translated_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307,
          "referenced_widgets": [
            "a70f8aba07c74bf1ae769eb2dff13cdb",
            "c33d663592ec4dfca0329b26beaeff42",
            "db6b02b9fe4d4b96bbef31319bac113b",
            "826e2ae31ffa4091b7fbcd37fe94dbef",
            "8cf8ef2f20b4401dba0a33923355242f",
            "bdb8c4661e934e86bf86f4fb9eec012c",
            "6cc3246fe1bd4ce1840f9ab06d541219",
            "3dc1c4662e1a4d91972be51c0388fa7a",
            "b38d0498ce4d447093d66424571e45f6",
            "0a2cca1fd94b493c8d270392023cd1e8",
            "69cabddd63444771b22318f10545eb71",
            "23d2b5df7d9b49008eb9637e5919c108",
            "f60eddd05bf241239c505b73ad032578",
            "31018765986f4b10a460843bb14c8ce2",
            "c2b81035268d445291117720cc79d239",
            "b7fbe887078d4b56b3e1d6a3185c5b72",
            "c1bc3655b47648e4b131fba21aaa0bc7",
            "60bc7c587f6e44d38f4188b5fbe80d31",
            "8722cf4d13d64224a25c75f69a257f87",
            "946fd736869943c9bd39ed4c4a559649",
            "a0bc705a16de457ea34cdd42237d4a0b",
            "dd2d599e19d64732b52c5ee2983a0c49",
            "bc1414b85dc7468a8f42185dfafdb6db",
            "49aac21a079341ac859f5a2e95f5a8b1",
            "20ad9d6f1b4542e0be43b72a39ced655",
            "32976d35803d45f983952b452960c8c9",
            "e60e736fad224159b4a067f1d1b8536c",
            "f037fbb2c1e14cf5a0abebc61b547e2a",
            "c8c92202d9264e21877e5a026832f4fb",
            "8fc5ace591e84c46b2c93c05d4d5982c",
            "72f03004a2f34777be12b5c87faefe9a",
            "0b3e29c8b85c436fa4ac6582ef1120eb",
            "b9afce69d42b4548be532f879d367a4e"
          ]
        },
        "id": "Ig2MSrqWPz3i",
        "outputId": "5fac9433-3759-4ad1-9d19-72c23df64459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/26.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a70f8aba07c74bf1ae769eb2dff13cdb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/45.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23d2b5df7d9b49008eb9637e5919c108"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/190104 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc1414b85dc7468a8f42185dfafdb6db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-44f5bb76b79c>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state = torch.load(model_filename, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation step 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches: 100%|██████████| 1783/1783 [11:34<00:00,  2.57it/s]\n"
          ]
        }
      ],
      "source": [
        "# Основной код\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config = get_config()\n",
        "\n",
        "# Получаем данные и токенизаторы\n",
        "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
        "\n",
        "# Создаём модель\n",
        "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
        "\n",
        "# Загружаем веса модели\n",
        "model_filename = f\"{config['model_folder']}/{config['model_basename']}09.pt\"\n",
        "state = torch.load(model_filename, map_location=device)\n",
        "model.load_state_dict(state['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "# Запускаем валидацию\n",
        "run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: print(msg), 0, None)\n",
        "\n",
        "# Пример перевода\n",
        "references = []  # Эталонные переводы\n",
        "hypotheses = []  # Предсказанные переводы\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "for batch in tqdm(val_dataloader, desc=\"Processing batches\"):\n",
        "    src_text = batch['src_text'][0]  # Исходный текст\n",
        "    tgt_text = batch['tgt_text'][0]  # Эталонный перевод\n",
        "    translated_text = translate_sentence(model, src_text, tokenizer_src, tokenizer_tgt, config['seq_len'], device)\n",
        "    references.append(tgt_text)\n",
        "    hypotheses.append(translated_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gXGy0aPYP2Kf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1274acff-a31a-4392-93a1-039fc61e037c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 34.22474095037862\n"
          ]
        }
      ],
      "source": [
        "# 7. Вычисление BLEU\n",
        "bleu_score = corpus_bleu(hypotheses, [references])\n",
        "print(f\"BLEU Score: {bleu_score.score}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLEU Score: 34.22474095037862"
      ],
      "metadata": {
        "id": "0UAj133tnD7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Пример вывода для проверки\n",
        "for i in tqdm(range(5), desc=\"Printing examples\"):  # Прогресс-бар для примеров\n",
        "    print(f\"Исходный текст: {references[i]}\")\n",
        "    print(f\"Эталонный перевод: {hypotheses[i]}\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBAWpOl-cKCC",
        "outputId": "8119fddc-7c21-45c7-8d9a-a41b900eebc8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Printing examples: 100%|██████████| 5/5 [00:00<00:00, 13469.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный текст: Правительствам, которым придется решать задачу повышения расходов, необходимо будет разработать целевые системы социальной защиты, которые защитят их бедных людей за счет выделения денежных средств или квазиденежных трансфертов.\n",
            "Эталонный перевод: Правительства , которые сталкиваются с большими расходами , должны разработать целевые системы социальной защиты , которые защищают своих бедных людей посредством денежных и денежных переводов .\n",
            "--------------------------------------------------\n",
            "Исходный текст: Нашей работой по экономическому развитию, сохранению мира, охране окружающей среды и здравоохранению, мы помогаем странам и сообществам строить лучшее, более свободное и процветающее будущее.\n",
            "Эталонный перевод: Нашей работой в развитии , сохранении мира , охране окружающей среды и здоровье , мы странам и сообществам строить лучшее , более будущее .\n",
            "--------------------------------------------------\n",
            "Исходный текст: Поскольку население из отказывающейся от евро страны продолжало бы хранить евро, уход из Европейского экономического и валютного союза не снизил бы уровень существующего благосостояния.\n",
            "Эталонный перевод: Поскольку люди из страны могут продолжать держать евро , оставляя ЕВС не приведет к потере существующего благосостояния .\n",
            "--------------------------------------------------\n",
            "Исходный текст: Подтвержден��е того, что эти реликвии холодной войны устарели как средства обеспечения безопасности – и, что на самом деле они совсем не безопасны - исходит от разных сторон.\n",
            "Эталонный перевод: , что эти холодной войны устарели как инструменты безопасности – и , действительно , они вызывают нестабильность – исходит от разнообразных рядов голосов .\n",
            "--------------------------------------------------\n",
            "Исходный текст: Мы можем иметь очень поверхностную информацию о компаниях, которые стоят за всеми этими удобствами и получают нашу информацию; но, помимо маркетинговой информации, сотрудники этих компаний являются для нас безликими и безымянными.\n",
            "Эталонный перевод: У нас может быть понимание того , что компании , за этими , выполняют наши данные ; но помимо маркетинга , реальные люди , которые управляют этими организациями , и .\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing examples: 100%|██████████| 5/5 [00:00<00:00, 13469.18it/s]Исходный текст: Правительствам, которым придется решать задачу повышения расходов, необходимо будет разработать целевые системы социальной защиты, которые защитят их бедных людей за счет выделения денежных средств или квазиденежных трансфертов.\n",
        "Эталонный перевод: Правительства , которые сталкиваются с большими расходами , должны разработать целевые системы социальной защиты , которые защищают своих бедных людей посредством денежных и денежных переводов .\n",
        "--------------------------------------------------\n",
        "Исходный текст: Нашей работой по экономическому развитию, сохранению мира, охране окружающей среды и здравоохранению, мы помогаем странам и сообществам строить лучшее, более свободное и процветающее будущее.\n",
        "Эталонный перевод: Нашей работой в развитии , сохранении мира , охране окружающей среды и здоровье , мы странам и сообществам строить лучшее , более будущее .\n",
        "--------------------------------------------------\n",
        "Исходный текст: Поскольку население из отказывающейся от евро страны продолжало бы хранить евро, уход из Европейского экономического и валютного союза не снизил бы уровень существующего благосостояния.\n",
        "Эталонный перевод: Поскольку люди из страны могут продолжать держать евро , оставляя ЕВС не приведет к потере существующего благосостояния .\n",
        "--------------------------------------------------\n",
        "Исходный текст: Подтвержден��е того, что эти реликвии холодной войны устарели как средства обеспечения безопасности – и, что на самом деле они совсем не безопасны - исходит от разных сторон.\n",
        "Эталонный перевод: , что эти холодной войны устарели как инструменты безопасности – и , действительно , они вызывают нестабильность – исходит от разнообразных рядов голосов .\n",
        "--------------------------------------------------\n",
        "Исходный текст: Мы можем иметь очень поверхностную информацию о компаниях, которые стоят за всеми этими удобствами и получают нашу информацию; но, помимо маркетинговой информации, сотрудники этих компаний являются для нас безликими и безымянными.\n",
        "Эталонный перевод: У нас может быть понимание того , что компании , за этими , выполняют наши данные ; но помимо маркетинга , реальные люди , которые управляют этими организациями , и .\n",
        "--------------------------------------------------"
      ],
      "metadata": {
        "id": "VjDwcYYUnGit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Создаём DataFrame из hypotheses и references\n",
        "df = pd.DataFrame({'Hypothesis': hypotheses, 'Reference': [ref[0] for ref in references]})\n",
        "\n",
        "# Сохраняем DataFrame в CSV\n",
        "df.to_csv('translations_dataframe.csv', index=False, encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "KPRm1Jj4cbz7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sRV4SnuUqgQ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a70f8aba07c74bf1ae769eb2dff13cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c33d663592ec4dfca0329b26beaeff42",
              "IPY_MODEL_db6b02b9fe4d4b96bbef31319bac113b",
              "IPY_MODEL_826e2ae31ffa4091b7fbcd37fe94dbef"
            ],
            "layout": "IPY_MODEL_8cf8ef2f20b4401dba0a33923355242f"
          }
        },
        "c33d663592ec4dfca0329b26beaeff42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdb8c4661e934e86bf86f4fb9eec012c",
            "placeholder": "​",
            "style": "IPY_MODEL_6cc3246fe1bd4ce1840f9ab06d541219",
            "value": "README.md: 100%"
          }
        },
        "db6b02b9fe4d4b96bbef31319bac113b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dc1c4662e1a4d91972be51c0388fa7a",
            "max": 26883,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b38d0498ce4d447093d66424571e45f6",
            "value": 26883
          }
        },
        "826e2ae31ffa4091b7fbcd37fe94dbef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a2cca1fd94b493c8d270392023cd1e8",
            "placeholder": "​",
            "style": "IPY_MODEL_69cabddd63444771b22318f10545eb71",
            "value": " 26.9k/26.9k [00:00&lt;00:00, 1.82MB/s]"
          }
        },
        "8cf8ef2f20b4401dba0a33923355242f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdb8c4661e934e86bf86f4fb9eec012c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cc3246fe1bd4ce1840f9ab06d541219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dc1c4662e1a4d91972be51c0388fa7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b38d0498ce4d447093d66424571e45f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a2cca1fd94b493c8d270392023cd1e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69cabddd63444771b22318f10545eb71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23d2b5df7d9b49008eb9637e5919c108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f60eddd05bf241239c505b73ad032578",
              "IPY_MODEL_31018765986f4b10a460843bb14c8ce2",
              "IPY_MODEL_c2b81035268d445291117720cc79d239"
            ],
            "layout": "IPY_MODEL_b7fbe887078d4b56b3e1d6a3185c5b72"
          }
        },
        "f60eddd05bf241239c505b73ad032578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1bc3655b47648e4b131fba21aaa0bc7",
            "placeholder": "​",
            "style": "IPY_MODEL_60bc7c587f6e44d38f4188b5fbe80d31",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "31018765986f4b10a460843bb14c8ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8722cf4d13d64224a25c75f69a257f87",
            "max": 45349681,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_946fd736869943c9bd39ed4c4a559649",
            "value": 45349681
          }
        },
        "c2b81035268d445291117720cc79d239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0bc705a16de457ea34cdd42237d4a0b",
            "placeholder": "​",
            "style": "IPY_MODEL_dd2d599e19d64732b52c5ee2983a0c49",
            "value": " 45.3M/45.3M [00:00&lt;00:00, 156MB/s]"
          }
        },
        "b7fbe887078d4b56b3e1d6a3185c5b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1bc3655b47648e4b131fba21aaa0bc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60bc7c587f6e44d38f4188b5fbe80d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8722cf4d13d64224a25c75f69a257f87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "946fd736869943c9bd39ed4c4a559649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0bc705a16de457ea34cdd42237d4a0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2d599e19d64732b52c5ee2983a0c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc1414b85dc7468a8f42185dfafdb6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49aac21a079341ac859f5a2e95f5a8b1",
              "IPY_MODEL_20ad9d6f1b4542e0be43b72a39ced655",
              "IPY_MODEL_32976d35803d45f983952b452960c8c9"
            ],
            "layout": "IPY_MODEL_e60e736fad224159b4a067f1d1b8536c"
          }
        },
        "49aac21a079341ac859f5a2e95f5a8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f037fbb2c1e14cf5a0abebc61b547e2a",
            "placeholder": "​",
            "style": "IPY_MODEL_c8c92202d9264e21877e5a026832f4fb",
            "value": "Generating train split: 100%"
          }
        },
        "20ad9d6f1b4542e0be43b72a39ced655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fc5ace591e84c46b2c93c05d4d5982c",
            "max": 190104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72f03004a2f34777be12b5c87faefe9a",
            "value": 190104
          }
        },
        "32976d35803d45f983952b452960c8c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b3e29c8b85c436fa4ac6582ef1120eb",
            "placeholder": "​",
            "style": "IPY_MODEL_b9afce69d42b4548be532f879d367a4e",
            "value": " 190104/190104 [00:01&lt;00:00, 215998.83 examples/s]"
          }
        },
        "e60e736fad224159b4a067f1d1b8536c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f037fbb2c1e14cf5a0abebc61b547e2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8c92202d9264e21877e5a026832f4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fc5ace591e84c46b2c93c05d4d5982c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f03004a2f34777be12b5c87faefe9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b3e29c8b85c436fa4ac6582ef1120eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9afce69d42b4548be532f879d367a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}