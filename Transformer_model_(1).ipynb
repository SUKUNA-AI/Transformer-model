{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qga-uK4-sReO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qga-uK4-sReO",
        "outputId": "1ebe305a-628d-4923-efd9-a4e5e1e3d5b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.optim as optim\n",
        "import warnings\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from pathlib import Path\n",
        "from typing import Any\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9197f202300f7323",
      "metadata": {
        "id": "9197f202300f7323"
      },
      "source": [
        "Здесь config нашей модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3ce4917714cb250",
      "metadata": {
        "id": "b3ce4917714cb250"
      },
      "outputs": [],
      "source": [
        "def get_config():\n",
        "    return {\n",
        "        \"batch_size\": 32,\n",
        "        \"num_epochs\": 10,\n",
        "        \"lr\": 2e-4,\n",
        "        \"seq_len\": 570,\n",
        "        \"d_model\": 512,\n",
        "        \"datasource\": 'Helsinki-NLP/news_commentary',\n",
        "        \"lang_src\": \"en\",\n",
        "        \"lang_tgt\": \"ru\",\n",
        "        \"model_folder\": \"weights\",\n",
        "        \"model_basename\": \"transformer_translate_model\",\n",
        "        \"preload\": None,\n",
        "        \"tokenizer_file\": \"tokenizer_{0}.json\",\n",
        "        \"experimental_name\": \"runs/transformer_translate_model\"\n",
        "    }\n",
        "\n",
        "def get_weights_file_path(config, epoch: str):\n",
        "    model_folder = config['model_folder']\n",
        "    model_basename = config['model_basename']\n",
        "    model_filename = f\"{model_basename}{epoch}.pt\"\n",
        "    return str(Path('.') / model_folder / model_filename)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c18cff7b7c94697f",
      "metadata": {
        "id": "c18cff7b7c94697f"
      },
      "source": [
        "Здесь сама модель трансформера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d92ffe1e1823aae",
      "metadata": {
        "id": "8d92ffe1e1823aae"
      },
      "outputs": [],
      "source": [
        "# Input Embeddings\n",
        "# Этот класс преобразует входные токены в векторные представления.\n",
        "class InputEmbeddings(nn.Module):\n",
        "    def __init__(self, d_model: int, vocab_size: int ):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model                # Размерность эмбеддингов (например, 512)\n",
        "        self.vocab_size = vocab_size          # Размер словаря\n",
        "        # Создаем слой эмбеддингов: каждому токену соответствует вектор размера d_model\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)  # d_model = 512 (размер эмбеддинга)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Умножаем эмбеддинги на корень из d_model для стабилизации градиентов\n",
        "        return self.embedding(x) * math.sqrt(self.d_model)\n",
        "\n",
        "# Positional Encodings\n",
        "# Этот класс добавляет информацию о позиции каждого токена в последовательности.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.seq_len = seq_len\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Создаем матрицу позиций размером (seq_len, d_model)\n",
        "        # Используем логарифмическую шкалу для повышения стабильности вычислений\n",
        "        pe = torch.zeros(seq_len, d_model)\n",
        "        # Создаем вектор позиций (seq_len, 1)\n",
        "        position = torch.arange(0, seq_len, dtype=torch.float32).unsqueeze(1)  # (seq_len, 1)\n",
        "        # Вычисляем коэффициенты масштабирования для синусов и косинусов\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        # Применяем sin к четным индексам и cos к нечетным индексам\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Добавляем дополнительное измерение, чтобы получить форму (1, seq_len, d_model)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        # Регистрируем pe как буфер, чтобы он не обновлялся во время обучения\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Прибавляем позиционные кодировки к входным эмбеддингам\n",
        "        # .require_grad_(False) гарантирует, что этот тензор не будет обучаться\n",
        "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)\n",
        "        return self.dropout(x)\n",
        "\n",
        "# Layer Normalization\n",
        "# Этот класс нормализует входной тензор по последнему измерению, чтобы ускорить обучение.\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, eps: float = 1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        # Параметры, которые обучаются: масштаб (alpha) и смещение (bias)\n",
        "        self.alpha = nn.Parameter(torch.ones(1))\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Вычисляем среднее и стандартное отклонение по последнему измерению\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        # Нормализуем x и применяем обучаемые параметры\n",
        "        return self.alpha * (x - mean) / (std + self.eps) + self.bias\n",
        "\n",
        "# Feed Forward Block\n",
        "# Этот блок представляет собой двухслойную полносвязную сеть с активацией и dropout.\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        # Первый линейный слой преобразует размерность с d_model до d_ff\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)  # W1 и b1\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # Второй линейный слой возвращает размерность обратно к d_model\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)    # W2 и b2\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Пропускаем x через первый слой, применяем ReLU, затем dropout и второй слой\n",
        "        x = self.dropout(torch.relu(self.linear1(x)))\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "# Multi-Head Attention\n",
        "# Этот блок реализует механизм многоголового внимания.\n",
        "class MultiHeadAttentionBlock(nn.Module):\n",
        "    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model                # Общая размерность модели\n",
        "        self.h = h                            # Количество голов\n",
        "        # Проверка: d_model должен быть кратен количеству голов\n",
        "        assert d_model % h == 0, \"d_model must be divisible by h\"\n",
        "\n",
        "        self.d_k = d_model // h               # Размерность каждой головы\n",
        "        # Линейные слои для вычисления Q, K, V\n",
        "        self.w_q = nn.Linear(d_model, d_model)  # Wq\n",
        "        self.w_k = nn.Linear(d_model, d_model)  # Wk\n",
        "        self.w_v = nn.Linear(d_model, d_model)  # Wv\n",
        "\n",
        "        # Линейный слой для объединения голов после внимания\n",
        "        self.w_o = nn.Linear(d_model, d_model)  # Wo\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    @staticmethod\n",
        "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
        "        # Получаем размерность ключей (d_k)\n",
        "        d_k = query.shape[-1]\n",
        "        # Вычисляем оценки внимания с масштабированием\n",
        "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        # Если маска задана, заполняем те позиции, где маска == 0, очень маленьким числом\n",
        "        if mask is not None:\n",
        "            attention_scores = attention_scores.masked_fill(mask == 0, -1e9)\n",
        "        # Применяем softmax для получения вероятностей внимания\n",
        "        attention_scores = attention_scores.softmax(dim=-1)\n",
        "        # Если задан dropout, применяем его к оценкам внимания\n",
        "        if dropout is not None:\n",
        "            attention_scores = dropout(attention_scores)\n",
        "        # Возвращаем результат (взвешенное значение) и сами оценки внимания\n",
        "        return (attention_scores @ value), attention_scores\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        # Применяем линейные преобразования для Q, K, V\n",
        "        query = self.w_q(q)  # (batch_size, seq_len, d_model)\n",
        "        key = self.w_k(k)    # (batch_size, seq_len, d_model)\n",
        "        value = self.w_v(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        # Изменяем форму тензоров для разделения на головы\n",
        "        # Преобразуем форму: (batch_size, seq_len, d_model) -> (batch_size, seq_len, h, d_k)\n",
        "        # Затем транспонируем, чтобы получить: (batch_size, h, seq_len, d_k)\n",
        "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Вычисляем механизм внимания и получаем выход и веса внимания\n",
        "        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n",
        "\n",
        "        # Транспонируем обратно и объединяем головы в один тензор:\n",
        "        # (batch_size, h, seq_len, d_k) -> (batch_size, seq_len, h, d_k) -> (batch_size, seq_len, d_model)\n",
        "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
        "\n",
        "        # Пропускаем объединенный тензор через итоговый линейный слой\n",
        "        return self.w_o(x)\n",
        "\n",
        "# Residual Connection\n",
        "# Этот класс реализует остаточные связи с нормализацией и dropout, чтобы стабилизировать обучение.\n",
        "class ResidualConnection(nn.Module):\n",
        "    def __init__(self, dropout: float):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.norm = LayerNormalization()\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        # Нормализуем вход, пропускаем через sublayer, применяем dropout и прибавляем исходный x (skip connection)\n",
        "        return x + self.dropout(sublayer(self.norm(x)))\n",
        "\n",
        "# Encoder Block\n",
        "# Этот блок объединяет в себе слой самовнимания и feed-forward блок с остаточными связями.\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForward, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.self_attention_block = self_attention_block\n",
        "        self.feed_forward_block = feed_forward_block\n",
        "        # Создаем два остаточных подключения: одно для самовнимания, другое для feed-forward\n",
        "        self.residual_connection = nn.ModuleList([ResidualConnection(dropout) for _ in range(2)])\n",
        "\n",
        "    def forward(self, x, scr_mask):\n",
        "        # Применяем остаточную связь для слоя самовнимания\n",
        "        x = self.residual_connection[0](x, lambda x: self.self_attention_block(x, x, x, scr_mask))\n",
        "        # Применяем остаточную связь для feed-forward блока\n",
        "        x = self.residual_connection[1](x, self.feed_forward_block)\n",
        "        return x\n",
        "\n",
        "# Encoder\n",
        "# Последовательность EncoderBlock'ов, завершающаяся финальной нормализацией.\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.norm = LayerNormalization()\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # Проходим последовательно по всем блокам энкодера\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        # Применяем финальную нормализацию\n",
        "        return self.norm(x)\n",
        "\n",
        "# Decoder Block\n",
        "# Этот блок декодера состоит из трёх частей: самовнимание, кросс-внимание и feed-forward, каждая с остаточной связью.\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, self_attention_block: MultiHeadAttentionBlock, cross_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForward, dropout:float) -> None:\n",
        "        super().__init__()\n",
        "        self.self_attention_block = self_attention_block\n",
        "        self.cross_attention_block = cross_attention_block\n",
        "        self.feed_forward_block = feed_forward_block\n",
        "        # Создаем три остаточных подключения для каждого подблока декодера\n",
        "        self.residual_connections = nn.ModuleList([ResidualConnection(dropout) for _ in range(3)])\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "        # Остаточная связь для самовнимания с target mask\n",
        "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\n",
        "        # Остаточная связь для кросс-внимания (между декодером и энкодером)\n",
        "        x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\n",
        "        # Остаточная связь для feed-forward блока\n",
        "        x = self.residual_connections[2](x, self.feed_forward_block)\n",
        "        return x\n",
        "\n",
        "# Decoder\n",
        "# Модуль декодера, состоящий из нескольких DecoderBlock'ов, завершающийся финальной нормализацией.\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.norm = LayerNormalization()\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "        # Последовательно проходим через все блоки декодера\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
        "        # Финальная нормализация\n",
        "        return self.norm(x)\n",
        "\n",
        "# Projection Layer\n",
        "# Преобразует выход декодера в вероятностное распределение по словарю.\n",
        "class ProjectionLayer(nn.Module):\n",
        "    def __init__(self, d_model: int, vocab_size: int ) -> None:\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Применяем линейное преобразование и логарифмический softmax для получения лог-вероятностей\n",
        "        return torch.log_softmax(self.proj(x), dim=-1)\n",
        "\n",
        "# Transformer\n",
        "# Объединяет энкодер, декодер и эмбеддинги с позиционными кодировками в одну модель.\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings,\n",
        "                 tgt_embed: InputEmbeddings, src_pos: PositionalEncoding, tgt_pos: PositionalEncoding,\n",
        "                 projection_layer: ProjectionLayer):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.src_pos = src_pos\n",
        "        self.tgt_pos = tgt_pos\n",
        "        self.projection_layer = projection_layer\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        # Применяем эмбеддинги и позиционные кодировки, затем энкодер\n",
        "        src = self.src_embed(src)\n",
        "        src = self.src_pos(src)\n",
        "        return self.encoder(src, src_mask)\n",
        "\n",
        "    def decode(self, encoder_output, src_mask, tgt, tgt_mask):\n",
        "        # Применяем эмбеддинги и позиционные кодировки к таргету, затем декодер\n",
        "        tgt = self.tgt_embed(tgt)\n",
        "        tgt = self.tgt_pos(tgt)\n",
        "        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n",
        "\n",
        "    def project(self, x):\n",
        "        # Преобразуем выход декодера в лог-вероятности по словарю\n",
        "        return self.projection_layer(x)\n",
        "\n",
        "\n",
        "# Функция для сборки модели Transformer с заданными гиперпараметрами.\n",
        "def build_transformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int,\n",
        "                      tgt_seq_len: int, d_model: int = 512, N: int = 6, h: int = 8,\n",
        "                      dropout: float = 0.1, d_ff: int = 2048) -> Transformer:\n",
        "    # Создаем эмбеддинги для исходного и целевого языков\n",
        "    src_embed = InputEmbeddings(d_model, src_vocab_size)\n",
        "    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n",
        "\n",
        "    # Создаем позиционные кодировки для исходного и целевого языков\n",
        "    src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\n",
        "    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\n",
        "\n",
        "    # Собираем блоки энкодера\n",
        "    encoder_blocks = []\n",
        "    for _ in range(N):\n",
        "        encoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        feed_forward_block = FeedForward(d_model, d_ff, dropout)\n",
        "        encoder_block = EncoderBlock(encoder_self_attention_block, feed_forward_block, dropout)\n",
        "        encoder_blocks.append(encoder_block)\n",
        "\n",
        "    # Собираем блоки декодера\n",
        "    decoder_blocks = []\n",
        "    for _ in range(N):\n",
        "        # Обратите внимание: в оригинальной архитектуре для декодера часто используются разные блоки для\n",
        "        # самовнимания и кросс-внимания. Здесь для простоты используются одинаковые блоки.\n",
        "        decoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        decoder_cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        feed_forward_block = FeedForward(d_model, d_ff, dropout)\n",
        "        decoder_block = DecoderBlock(decoder_self_attention_block, decoder_cross_attention_block, feed_forward_block, dropout)\n",
        "        decoder_blocks.append(decoder_block)\n",
        "\n",
        "    # Инициализируем энкодер и декодер, используя ModuleList для последовательности блоков\n",
        "    encoder = Encoder(nn.ModuleList(encoder_blocks))\n",
        "    decoder = Decoder(nn.ModuleList(decoder_blocks))\n",
        "\n",
        "    # Создаем проекционный слой для получения лог-вероятностей по словарю целевого языка\n",
        "    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n",
        "\n",
        "    # Собираем финальный Transformer\n",
        "    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n",
        "\n",
        "    # Инициализация параметров модели с помощью Xavier uniform\n",
        "    for p in transformer.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "    return transformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57a1ee07d715ff65",
      "metadata": {
        "id": "57a1ee07d715ff65"
      },
      "source": [
        "Здесь наш датасет и его обработка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38c6a9b67d6f3a62",
      "metadata": {
        "id": "38c6a9b67d6f3a62"
      },
      "outputs": [],
      "source": [
        "class BiLanguageDataset(Dataset):\n",
        "    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len) -> None:\n",
        "        # Здесь мы инициализируем наш датасет для двуязычных данных,\n",
        "        # чтобы модель могла шибко круто учиться переводить тексты.\n",
        "        super().__init__()\n",
        "        self.ds = ds  # Наш супер датасет с парами переводов.\n",
        "        self.tokenizer_src = tokenizer_src  # Токенизатор для исходного языка (например, английский).\n",
        "        self.tokenizer_tgt = tokenizer_tgt  # Токенизатор для целевого языка (например, русский).\n",
        "        self.src_lang = src_lang  # Код исходного языка.\n",
        "        self.tgt_lang = tgt_lang  # Код целевого языка.\n",
        "        self.seq_len = seq_len  # Максимальная длина последовательности, чтобы всё было аккуратно.\n",
        "\n",
        "        # Получаем специальные токены: старт ([SOS]), конец ([EOS]) и паддинг ([PAD]),\n",
        "        # чтобы модель понимала, когда начинать и заканчивать работу с текстом.\n",
        "        self.sos_token = torch.tensor([tokenizer_src.token_to_id('[SOS]')], dtype=torch.int64)\n",
        "        self.eos_token = torch.tensor([tokenizer_src.token_to_id('[EOS]')], dtype=torch.int64)\n",
        "        self.pad_token = torch.tensor([tokenizer_src.token_to_id('[PAD]')], dtype=torch.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Возвращаем количество элементов в датасете – быстро\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, index: Any) -> Any:\n",
        "        # Получаем пару переводов по индексу\n",
        "        src_target_pair = self.ds[index]\n",
        "        src_text = src_target_pair['translation'][self.src_lang]  # Исходный текст.\n",
        "        tgt_text = src_target_pair['translation'][self.tgt_lang]  # Перевод.\n",
        "\n",
        "        # Токенизируем тексты в последовательности токенов.\n",
        "        enc_input_tokens = self.tokenizer_src.encode(src_text).ids  # Токены для энкодера.\n",
        "        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids  # Токены для декодера.\n",
        "\n",
        "        # Вычисляем количество токенов, которые надо добавить, чтобы итоговая длина стала ровно seq_len.\n",
        "        # Для энкодера учитываем, что добавляем [SOS] и [EOS] токены.\n",
        "        enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2\n",
        "        # Для декодера добавляем только [SOS] (а [EOS] добавляется уже к меткам).\n",
        "        dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1\n",
        "\n",
        "        # Если предложение слишком длинное, то не сможем уместить его в seq_len — об этом сигнализируем.\n",
        "        if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n",
        "            raise ValueError('Sentence is too long')\n",
        "\n",
        "        # Формируем вход для энкодера: [SOS] + токены + [EOS] + заполнение (padding)\n",
        "        encoder_input = torch.cat(\n",
        "            [\n",
        "                self.sos_token,\n",
        "                torch.tensor(enc_input_tokens, dtype=torch.int64),\n",
        "                self.eos_token,\n",
        "                torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype=torch.int64)\n",
        "            ]\n",
        "        )\n",
        "        # Формируем вход для декодера: [SOS] + токены + заполнение (padding)\n",
        "        decoder_input = torch.cat(\n",
        "            [\n",
        "                self.sos_token,\n",
        "                torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
        "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64)\n",
        "            ]\n",
        "        )\n",
        "        # Формируем метки (label) для обучения: токены + [EOS] + заполнение (padding)\n",
        "        label = torch.cat(\n",
        "            [\n",
        "                torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
        "                self.eos_token,\n",
        "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Проверяем, что длина каждой последовательности ровно seq_len\n",
        "        assert encoder_input.size(0) == self.seq_len\n",
        "        assert decoder_input.size(0) == self.seq_len\n",
        "        assert label.size(0) == self.seq_len\n",
        "\n",
        "        # Возвращаем словарь с входами, масками и оригинальными текстами\n",
        "        return {\n",
        "            'encoder_input': encoder_input,  # Вход для энкодера.\n",
        "            'decoder_input': decoder_input,  # Вход для декодера.\n",
        "            # Маска для энкодера: отмечаем реальные токены (без паддинга).\n",
        "            'encoder_mask': (encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(),\n",
        "            # Маска для декодера: учитываем и паддинг, и каузальную маску, чтобы не подсматривать будущее.\n",
        "            'decoder_mask': (decoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int() & causal_mask(decoder_input.size(0)),\n",
        "            'label': label,            # Метки для обучения.\n",
        "            'src_text': src_text,      # Исходный текст, чтобы мы могли вспоминать, откуда всё началось.\n",
        "            'tgt_text': tgt_text       # Целевой текст — результат, к которому стремимся.\n",
        "        }\n",
        "\n",
        "# Функция для создания каузальной маски, которая запрещает модели \"подглядывать\" будущее при генерации.\n",
        "def causal_mask(size):\n",
        "    # Создаем верхнюю треугольную матрицу с единицами выше диагонали, начиная с diagonal=1.\n",
        "    mask = torch.triu(torch.ones(1, size, size), diagonal=1).type(torch.int)\n",
        "    # Возвращаем булеву маску: True там, где можно смотреть (и учиться на ошибках), и False там, где нельзя.\n",
        "    return mask == 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aca369240f223e50",
      "metadata": {
        "id": "aca369240f223e50"
      },
      "source": [
        "Здесь обучение модели\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "221aee2d5b2bdbb1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "da17a031275945c5a8f7a0bc23b756c7",
            "2f0feeaa5d3e45b3a1edd76a2e719f84",
            "78b70917e22d4db7b47e42c649931c44",
            "e8a7ea0236574c9795ce7f8fc4f78537",
            "45bb98d4de944d8e9ee8d65a6ce41f16",
            "4c307381abc44f56823c844f8892c61d",
            "c92815058b914c858fe3f39fa81f88a3",
            "f4e2eec0848a4b79a59caef658355632",
            "bf027fb932fa406bac66af3dc43edf5d",
            "3acd089fe6e741638a19915c131af406",
            "8fe350be9e8e4c66b038e98fc19014ca",
            "57302ed877d7443395a8b5e21021e0b1",
            "04ba5114bec441d0a0955ad0bc508193",
            "e3f8a250e4334ddc95964b96019c9909",
            "0ebd3cdc1ebf4a80af80719f5e042cc8",
            "5a4cb79c9a4f4997a319dbea515341c3",
            "b50bed43e23749cc8f212061499f837b",
            "565afc75ddcc4541b1fb43446e73bafc",
            "b78f9cefd6f2421aa1a63918b6e0206e",
            "dbf1313ad4054ea3be7628fef9a1b99f",
            "c0b4952a794e479caddd7c3d183dcb50",
            "225d4f70c2f14f598e160eba0fb1b1a5",
            "13436155f4e0445587ab0957a71b1448",
            "553800040db04888bd7f05476c797c8a",
            "85af20ef3dd44267a975810041d83a40",
            "aa9e3ee3fe3b486ea56db4c38678ea17",
            "ee620753b17b4b00a35d63a5f8557943",
            "7fc4c9939ef34ece98b930b20c796732",
            "f4c450081c964b6f9d46daaa075bc7f6",
            "ec19e03613f84da1ad1c9bde3105f9db",
            "457302a4607e49a59a1661f32693b363",
            "f0adc10605a0472c838a92486851a928",
            "6c879bd9644e4991ac7a8e809f043630"
          ]
        },
        "id": "221aee2d5b2bdbb1",
        "outputId": "0f8c9d51-19e9-49c5-969d-db4f2d63ac0f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da17a031275945c5a8f7a0bc23b756c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/26.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57302ed877d7443395a8b5e21021e0b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/45.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13436155f4e0445587ab0957a71b1448",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/190104 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max length of source sentence: 222\n",
            "Max length of target sentence: 553\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing epoch 00: 100%|██████████| 5347/5347 [1:05:41<00:00,  1.36it/s, loss=4.922]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: Among the reasons the American military is committed to respect for the Geneva Conventions is a concern about reciprocity.\n",
            "Target: Одной из причин, по которым американские военнослужащие обязаны уважать Женевские Соглашения, является беспокойство о взаимности.\n",
            "Predicted: Среди американских военных действий в отношении является причиной .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: It is generally agreed that China’s impressive economic achievements during the last three decades are largely the result of the radical reform of its economic system.\n",
            "Target: В основном, все согласны с тем, что впечатляющие экономические достижения Китая за последние три десятилетия в большой степени являются результатом радикальной реформы его экономической системы.\n",
            "Predicted: Это , в основном , отражает экономические последствия Китая в последние годы , в основном , в основном , в экономической реформы .\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing epoch 01: 100%|██████████| 5347/5347 [1:05:40<00:00,  1.36it/s, loss=3.907]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: But today, Khrushchev is remembered mostly for his contribution to the demise of Stalinism – and, via Mikhail Gorbachev, whose hero he was, ultimately for helping to bring about communism’s demise.\n",
            "Target: Но сегодня, Хрущева помнят главным образом благодаря его вкладу в разоблачение и уничтожение сталинизма – а также, благодаря Михаилу Горбачеву, чьим героем он был, и, в конечном счете, благодаря тому, что опосредованно Хрущев помог вызвать упадок коммунизма.\n",
            "Predicted: Но сегодня Хрущев , в основном , его вклад в – и , через Михаила Саакашвили , чья дочь , в конечном итоге , помогает о коммунизма .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: If it can, then perhaps watching other countries suffer will help convince the local political elite to consent to adjustment.\n",
            "Target: Если она сможет, тогда наблюдение за тем, как страдают другие страны, возможно, поможет убедить местную политическую элиту согласиться на преобразования.\n",
            "Predicted: Если это может , то , что может произойти другие страны , , помогут убедить местные политические элиты к соглашению .\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing epoch 02: 100%|██████████| 5347/5347 [1:05:42<00:00,  1.36it/s, loss=3.694]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: (There is some new evidence, uncovered by Jim Pfaus at Concordia University in Canada, that desensitization may be affecting women consumers of pornography as well.)\n",
            "Target: (Есть новые свидетельства, открытые Джимом Пфаусом из университета Конкордия в Канаде, что десенсибилизация может также влиять на женщин, потребляющих порнографию).\n",
            "Predicted: ( Есть некоторые новые доказательства , в университете в Канаде , что может быть женщин , и ).\n",
            "--------------------------------------------------------------------------------\n",
            "Source: Nordbanken had become fully state-owned and a new management was put in place to restore the bank to viability.\n",
            "Target: «Nordbanken» полностью перешел в собственность государства, и чтобы восстановить жизнеспособность банка, было назначено новое руководствоии.\n",
            "Predicted: « » стал полностью государством и новым управлением , в банк для жизнеспособности .\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing epoch 03: 100%|██████████| 5347/5347 [1:05:42<00:00,  1.36it/s, loss=3.263]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: This applies to the world economy today.\n",
            "Target: Это можно применить к сегодняшней мировой экономике.\n",
            "Predicted: Это применимо к мировой экономике .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: In short, they fear that all of the sacrifices made for price stability will have been in vain.\n",
            "Target: Короче говоря, они опасаются, что все жертвы, принесенные ими во имя стабильности цен, окажутся напрасны.\n",
            "Predicted: Короче говоря , они опасаются , что все жертвы , которые за стабильность цен , были .\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing epoch 04: 100%|██████████| 5347/5347 [1:05:43<00:00,  1.36it/s, loss=3.142]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: Absent further trade agreements, there is a big risk that the pace of globalization will slow, with profound consequences for global poverty and welfare.\n",
            "Target: При дальнейшем отсутствии торговых соглашений существует большой риск, что темп глобализации замедлится с глубокими последствиями для глобальной бедности и благосостояния.\n",
            "Predicted: При отсутствии дальнейших торговых соглашений существует большая вероятность того , что скорость глобализации замедлится , с серьезными последствиями для глобальной бедности и благосостояния .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: China’s macroeconomic policies are probably still too “administrative.”\n",
            "Target: Возможно, макроэкономическая политика Китая по-прежнему является слишком «административной».\n",
            "Predicted: политика Китая , вероятно , тоже является « административной ».\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing epoch 05: 100%|██████████| 5347/5347 [1:05:42<00:00,  1.36it/s, loss=2.854]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: But there is also a growing realization that malaria is a disaster that must be addressed.\n",
            "Target: Но наряду с этим, растет и осознание того, что с бедствием под названием малярия необходимо бороться.\n",
            "Predicted: Но также растущее осознание того , что малярия – это катастрофа , которую необходимо решить .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: Regardless of what the Saakashvili government claims about his opponents, our political orientation is not pro-Russian, but pro-Georgian.\n",
            "Target: Вне зависимости от того, что правительство Саакашвили говорит о своих оппонентах, наша политическая ориентация не пророссийская, а прогрузинская.\n",
            "Predicted: Независимо от того , что правительство Саакашвили заявляет о своих оппонентов , наша политическая ориентация не является , а .\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing epoch 06: 100%|██████████| 5347/5347 [1:05:43<00:00,  1.36it/s, loss=2.837]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: The IIF believes that GDP could be fully 5% lower after five years, with unemployment more than 7% higher.\n",
            "Target: ИМФ считает, что ВВП после пяти лет может сократиться на целые 5%, а безработица может оказаться на 7% выше.\n",
            "Predicted: полагает , что ВВП может быть в целых 5 % ниже , чем на пять лет , а безработица выше на 7 %.\n",
            "--------------------------------------------------------------------------------\n",
            "Source: Indeed, China is on the precipice of becoming an environmental wasteland.\n",
            "Target: Действительно, Китай находится на гране превращения в экологическую свалку.\n",
            "Predicted: Действительно , Китай находится на краю пропасти , став экологические .\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing epoch 07: 100%|██████████| 5347/5347 [1:05:41<00:00,  1.36it/s, loss=2.593]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: The opposition must build itself as a credible and attractive alternative to the Assad regime, and the regime’s international and regional critics must assist in that process.\n",
            "Target: Оппозиция должна проявить себя как надежная и привлекательная альтернатива режиму Асада, а международные и региональные критики режима должны помогать в этом процессе.\n",
            "Predicted: Оппозиция должна построить себе как , так и привлекательную альтернативу режиму Асада , и международные и региональные критики должны помочь в этом процессе .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: Lastly, don't take too dogmatic a view of corruption and or the looting of the public coffers; they are part of the system.\n",
            "Target: И, наконец – не судите слишком строго коррупцию и грабеж общественной казны – это часть системы.\n",
            "Predicted: И , наконец , не следует слишком взгляд на коррупцию и государственной ; они являются частью системы .\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing epoch 08: 100%|██████████| 5347/5347 [1:05:45<00:00,  1.36it/s, loss=2.637]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: After all, while his policy of confrontation has generated high levels of violence, tolerance of the drug cartels corrupted state institutions, sowing the ground for the problem in the first place.\n",
            "Target: В конце концов, в то время как его политика конфронтации привела к высокому уровню насилия, толерантность к наркокартелям привела к коррупции государственных учреждений, изначально создавая основу для проблем.\n",
            "Predicted: В конце концов , в то время как его политика конфронтации привела к высокому уровню насилия , терпимость к государственных институтов , почву для проблемы в первом месте .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: If you spin the bottle and create an eddy inside it, the water will flow out much faster and more smoothly.\n",
            "Target: Если Вы будете вращать бутылку и создадите внутри нее воронку, вода вытечет намного быстрее и ровным потоком.\n",
            "Predicted: Если вы и в ней , вода гораздо быстрее и гладко .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 09: 100%|██████████| 5347/5347 [1:05:41<00:00,  1.36it/s, loss=2.522]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: On April 29, 1865, this radical proposal scraped through the Massachusetts General Court (the state’s bi-cameral legislature), owing to intense lobbying and the goodwill generated by Harvard alumni’s distinguished service for the Union during the Civil War.\n",
            "Target: 29 апреля 1865 года это радикальное предложение прошло через Главный суд штата Массачусетс (двухпалатный законодательный орган штата), вследствие интенсивного лоббирования и доброй воли, которые обеспечили заслуги выпускников Гарварда перед Союзом во времена Гражданской войны.\n",
            "Predicted: 29 апреля , , данное радикальное предложение судом ( - законодательство государства ), вызванное интенсивным и , в для Союза во время гражданской войны .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: So long as a large number of American troops remains as an occupying force, they serve as a recruiting tool for insurgents.\n",
            "Target: До тех пор пока большое количество американских войск находится в стране в качестве оккупационной силы, они являются идеальным орудием вербовки для мятежников.\n",
            "Predicted: До тех пор , пока большое количество американских войск остается оккупационной силой , они служат инструментом для повстанцев .\n"
          ]
        }
      ],
      "source": [
        "def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n",
        "    # Берем индексы специальных токенов для начала и конца перевода – [SOS] и [EOS]\n",
        "    sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n",
        "    eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n",
        "\n",
        "    # Пропускаем источник через энкодер, чтобы получить его представление\n",
        "    encoder_output = model.encode(source, source_mask)\n",
        "    # Инициализируем декодер с токеном [SOS] – стартуем наше приключение перевода\n",
        "    decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(source).to(device)\n",
        "\n",
        "    # Генерируем перевод токен за токеном, пока не достигнем максимальной длины или не встретим [EOS]\n",
        "    while True:\n",
        "        if decoder_input.size(1) == max_len:\n",
        "            break\n",
        "        # Создаем каузальную маску для декодера, чтобы он не заглядывал в будущее\n",
        "        decoder_mask = causal_mask(decoder_input.size(1)).type_as(source).to(device)\n",
        "\n",
        "        # Пропускаем данные через декодер и получаем вероятность следующего токена\n",
        "        out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n",
        "        prob = model.project(out[:, -1])\n",
        "        # Выбираем токен с наивысшей вероятностью\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        # Добавляем выбранный токен к уже сгенерированной последовательности\n",
        "        decoder_input = torch.cat(\n",
        "            [\n",
        "                decoder_input,\n",
        "                torch.empty(1, 1).type_as(source).fill_(next_word.item()).to(device)\n",
        "            ], dim=1\n",
        "        )\n",
        "\n",
        "        # Если встретился [EOS] – завершаем генерацию\n",
        "        if next_word == eos_idx:\n",
        "            break\n",
        "    return decoder_input.squeeze(0)\n",
        "\n",
        "\n",
        "def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, global_state, writer, num_examples=2):\n",
        "    # Переводим модель в режим валидации, чтобы градиенты не мешали нашему спокойствию\n",
        "    model.eval()\n",
        "    count = 0\n",
        "\n",
        "    # Списки для хранения исходных текстов, эталонных и предсказанных переводов – чтобы сравнить и полюбоваться результатами\n",
        "    source_texts = []\n",
        "    expected = []\n",
        "    predicted = []\n",
        "\n",
        "    console_width = 80\n",
        "    with torch.no_grad():\n",
        "        # Проходим по валидационному датасету\n",
        "        for batch in validation_ds:\n",
        "            count += 1\n",
        "            encoder_input = batch['encoder_input'].to(device)\n",
        "            encoder_mask = batch['encoder_mask'].to(device)\n",
        "\n",
        "            assert encoder_input.size(0) == 1, \"Batch size must be 1 for validation\"\n",
        "\n",
        "            # Генерируем перевод с помощью жадного декодера\n",
        "            model_out = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
        "            current_src_text = batch['src_text'][0]  # Исходный текст из батча\n",
        "            target_text = batch['tgt_text'][0]         # Правильный перевод\n",
        "            model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "            # Сохраняем данные для последующего сравнения\n",
        "            source_texts.append(current_src_text)\n",
        "            expected.append(target_text)\n",
        "            predicted.append(model_out_text)\n",
        "\n",
        "            # Выводим в консоль результат для наслаждения прогрессом\n",
        "            print_msg('-' * console_width)\n",
        "            print_msg(f\"Source: {current_src_text}\")\n",
        "            print_msg(f\"Target: {target_text}\")\n",
        "            print_msg(f\"Predicted: {model_out_text}\")\n",
        "\n",
        "            if count >= num_examples:\n",
        "                break\n",
        "\n",
        "\n",
        "def get_all_sentences(ds, lang):\n",
        "    # Генератор, который последовательно возвращает каждое предложение для указанного языка\n",
        "    for item in ds:\n",
        "        yield item['translation'][lang]\n",
        "\n",
        "\n",
        "def build_tokenizer(config, ds, lang):\n",
        "    # Формируем путь к файлу токенизатора для данного языка\n",
        "    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n",
        "    if not Path.exists(tokenizer_path):\n",
        "        # Если токенизатора еще нет – создаем его с нуля\n",
        "        tokenizer = Tokenizer(WordLevel(unk_token='[UNK]'))\n",
        "        tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = WordLevelTrainer(special_tokens=['[UNK]', '[PAD]', '[SOS]', '[EOS]'], min_frequence=2)\n",
        "        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n",
        "        # Сохраняем токенизатор, чтобы потом не тратить время на его пересоздание\n",
        "        tokenizer.save(str(tokenizer_path))\n",
        "    else:\n",
        "        # Если файл уже существует – просто загружаем токенизатор\n",
        "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "def get_ds(config):\n",
        "    # Загружаем датасет новостных комментариев\n",
        "    ds_row = load_dataset('Helsinki-NLP/news_commentary', f'{config[\"lang_src\"]}-{config[\"lang_tgt\"]}', split='train')\n",
        "    # Строим токенизаторы для исходного и целевого языков\n",
        "    tokenizer_src = build_tokenizer(config, ds_row, config['lang_src'])\n",
        "    tokenizer_tgt = build_tokenizer(config, ds_row, config['lang_tgt'])\n",
        "\n",
        "    # Разбиваем датасет на обучающую и валидационную выборки (90%/10%)\n",
        "    train_ds_size = int(0.9 * len(ds_row))\n",
        "    val_ds_size = len(ds_row) - train_ds_size\n",
        "    train_ds_raw, val_ds_raw = random_split(ds_row, [train_ds_size, val_ds_size])\n",
        "\n",
        "    # Создаем экземпляры нашего датасета для обоих наборов данных\n",
        "    train_ds = BiLanguageDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "    val_ds = BiLanguageDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "\n",
        "    # Вычисляем максимальную длину предложений для каждого языка\n",
        "    max_len_src = 0\n",
        "    max_len_tgt = 0\n",
        "    for item in ds_row:\n",
        "        src_ids = tokenizer_src.encode(item['translation'][config['lang_src']]).ids\n",
        "        tgt_ids = tokenizer_src.encode(item['translation'][config['lang_tgt']]).ids\n",
        "        max_len_src = max(max_len_src, len(src_ids))\n",
        "        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
        "    print(f'Max length of source sentence: {max_len_src}')\n",
        "    print(f'Max length of target sentence: {max_len_tgt}')\n",
        "\n",
        "    # Создаем DataLoader'ы для удобного перебора данных: обучающего и валидационного\n",
        "    train_dataloader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
        "    val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=True)\n",
        "\n",
        "    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt\n",
        "\n",
        "\n",
        "def get_model(config, vocab_src_len, vocab_tgt_len):\n",
        "    # Создаем трансформер для перевода\n",
        "    model = build_transformer(vocab_src_len, vocab_tgt_len, config['seq_len'], config['seq_len'], config['d_model'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(config):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Using device: {device}')\n",
        "\n",
        "    # Создаем папку для сохранения весов модели\n",
        "    Path(config['model_folder']).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Загружаем датасеты и токенизаторы\n",
        "    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
        "    # Строим модель-переводчик и перемещаем ее на нужное устройство\n",
        "    model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
        "\n",
        "    # Инициализируем логгер для TensorBoard\n",
        "    writer = SummaryWriter(config['experimental_name'])\n",
        "\n",
        "    # Настраиваем оптимизатор для модели – Adam\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n",
        "\n",
        "    initial_epoch = 0\n",
        "    global_step = 0\n",
        "    # Если задан путь к предобученной модели, загружаем её, чтобы не начинать все с нуля\n",
        "    if config['preload']:\n",
        "        model_filename = get_weights_file_path(config, config['preload'])\n",
        "        print(f'Preloaded model: {model_filename}')\n",
        "        state = torch.load(model_filename)\n",
        "        initial_epoch = state['epoch'] + 1\n",
        "        optimizer.load_state_dict(state['optimizer_state_dict'])\n",
        "        global_step = state['global_step']\n",
        "\n",
        "    # Определяем функцию потерь с учетом игнорирования [PAD]-токена и с label smoothing – для стабильного обучения\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
        "\n",
        "    # Основной цикл обучения по эпохам\n",
        "    for epoch in range(initial_epoch, config['num_epochs']):\n",
        "        batch_iterator = tqdm(train_dataloader, desc=f'Processing epoch {epoch:02d}')\n",
        "\n",
        "        for batch in batch_iterator:\n",
        "            model.train()  # Переводим модель в режим обучения\n",
        "\n",
        "            # Переносим все данные на выбранное устройство\n",
        "            encoder_input = batch['encoder_input'].to(device)\n",
        "            decoder_input = batch['decoder_input'].to(device)\n",
        "            encoder_mask = batch['encoder_mask'].to(device)\n",
        "            decoder_mask = batch['decoder_mask'].to(device)\n",
        "\n",
        "            # Прямой проход через модель: энкодер, декодер и проекция на словарь целевого языка\n",
        "            encoder_output = model.encode(encoder_input, encoder_mask)\n",
        "            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
        "            proj_output = model.project(decoder_output)\n",
        "\n",
        "            label = batch['label'].to(device)\n",
        "\n",
        "            # Вычисляем значение потерь\n",
        "            loss = loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n",
        "            batch_iterator.set_postfix({f\"loss\": f\"{loss.item():6.3f}\"})\n",
        "\n",
        "            # Логируем потери в TensorBoard\n",
        "            writer.add_scalar('train_loss', loss.item(), global_step)\n",
        "            writer.flush()\n",
        "\n",
        "            loss.backward()  # Обратное распространение ошибки\n",
        "            optimizer.step()  # Обновляем веса модели\n",
        "            optimizer.zero_grad()  # Обнуляем градиенты для следующей итерации\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        # После каждой эпохи проводим валидацию, чтобы убедиться, что мы идем в правильном направлении\n",
        "        run_validation(\n",
        "            model,\n",
        "            val_dataloader,\n",
        "            tokenizer_src,\n",
        "            tokenizer_tgt,\n",
        "            config['seq_len'],\n",
        "            device,\n",
        "            lambda msg: batch_iterator.write(msg),  # Функция для вывода сообщений\n",
        "            global_step,                         # Глобальный шаг, как отсчет нашего  пути\n",
        "            writer                               # Логгер\n",
        "        )\n",
        "\n",
        "        # Сохраняем модель после каждой эпохи\n",
        "        model_filename = get_weights_file_path(config, f'{epoch:02d}')\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'global_step': global_step\n",
        "        }, model_filename)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Загружаем конфигурацию и запускаем обучение модели – да начнется наше приключение перевода!\n",
        "    config = get_config()\n",
        "    train_model(config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: It is generally agreed that China’s impressive economic achievements during the last three decades are largely the result of the radical reform of its economic system.\n",
        "Target: В основном, все согласны с тем, что впечатляющие экономические достижения Китая за последние три десятилетия в большой степени являются результатом радикальной реформы его экономической системы.\n",
        "Predicted: Это , в основном , отражает экономические последствия Китая в последние годы , в основном , в основном , в экономической реформы .\n",
        "Processing epoch 01: 100%|██████████| 5347/5347 [1:05:40<00:00,  1.36it/s, loss=3.907]\n",
        "--------------------------------------------------------------------------------\n",
        "Source: But today, Khrushchev is remembered mostly for his contribution to the demise of Stalinism – and, via Mikhail Gorbachev, whose hero he was, ultimately for helping to bring about communism’s demise.\n",
        "Target: Но сегодня, Хрущева помнят главным образом благодаря его вкладу в разоблачение и уничтожение сталинизма – а также, благодаря Михаилу Горбачеву, чьим героем он был, и, в конечном счете, благодаря тому, что опосредованно Хрущев помог вызвать упадок коммунизма.\n",
        "Predicted: Но сегодня Хрущев , в основном , его вклад в – и , через Михаила Саакашвили , чья дочь , в конечном итоге , помогает о коммунизма .\n",
        "--------------------------------------------------------------------------------\n",
        "Source: If it can, then perhaps watching other countries suffer will help convince the local political elite to consent to adjustment.\n",
        "Target: Если она сможет, тогда наблюдение за тем, как страдают другие страны, возможно, поможет убедить местную политическую элиту согласиться на преобразования.\n",
        "Predicted: Если это может , то , что может произойти другие страны , , помогут убедить местные политические элиты к соглашению .\n",
        "Processing epoch 02: 100%|██████████| 5347/5347 [1:05:42<00:00,  1.36it/s, loss=3.694]\n",
        "--------------------------------------------------------------------------------\n",
        "Source: (There is some new evidence, uncovered by Jim Pfaus at Concordia University in Canada, that desensitization may be affecting women consumers of pornography as well.)\n",
        "Target: (Есть новые свидетельства, открытые Джимом Пфаусом из университета Конкордия в Канаде, что десенсибилизация может также влиять на женщин, потребляющих порнографию).\n",
        "Predicted: ( Есть некоторые новые доказательства , в университете в Канаде , что может быть женщин , и ).\n",
        "--------------------------------------------------------------------------------\n",
        "Source: Nordbanken had become fully state-owned and a new management was put in place to restore the bank to viability.\n",
        "Target: «Nordbanken» полностью перешел в собственность государства, и чтобы восстановить жизнеспособность банка, было назначено новое руководствоии.\n",
        "Predicted: « » стал полностью государством и новым управлением , в банк для жизнеспособности .\n",
        "Processing epoch 03: 100%|██████████| 5347/5347 [1:05:42<00:00,  1.36it/s, loss=3.263]\n",
        "--------------------------------------------------------------------------------\n",
        "Source: This applies to the world economy today.\n",
        "Target: Это можно применить к сегодняшней мировой экономике.\n",
        "Predicted: Это применимо к мировой экономике .\n",
        "--------------------------------------------------------------------------------\n",
        "Source: In short, they fear that all of the sacrifices made for price stability will have been in vain.\n",
        "Target: Короче говоря, они опасаются, что все жертвы, принесенные ими во имя стабильности цен, окажутся напрасны.\n",
        "Predicted: Короче говоря , они опасаются , что все жертвы , которые за стабильность цен , были .\n",
        "Processing epoch 04: 100%|██████████| 5347/5347 [1:05:43<00:00,  1.36it/s, loss=3.142]\n",
        "--------------------------------------------------------------------------------\n",
        "Source: Absent further trade agreements, there is a big risk that the pace of globalization will slow, with profound consequences for global poverty and welfare.\n",
        "Target: При дальнейшем отсутствии торговых соглашений существует большой риск, что темп глобализации замедлится с глубокими последствиями для глобальной бедности и благосостояния.\n",
        "Predicted: При отсутствии дальнейших торговых соглашений существует большая вероятность того , что скорость глобализации замедлится , с серьезными последствиями для глобальной бедности и благосостояния .\n",
        "--------------------------------------------------------------------------------\n",
        "Source: China’s macroeconomic policies are probably still too “administrative.”\n",
        "Target: Возможно, макроэкономическая политика Китая по-прежнему является слишком «административной».\n",
        "Predicted: политика Китая , вероятно , тоже является « административной ».\n",
        "Processing epoch 05: 100%|██████████| 5347/5347 [1:05:42<00:00,  1.36it/s, loss=2.854]\n",
        "--------------------------------------------------------------------------------\n",
        "Source: But there is also a growing realization that malaria is a disaster that must be addressed.\n",
        "Target: Но наряду с этим, растет и осознание того, что с бедствием под названием малярия необходимо бороться.\n",
        "Predicted: Но также растущее осознание того , что малярия – это катастрофа , которую необходимо решить .\n",
        "--------------------------------------------------------------------------------\n",
        "Source: Regardless of what the Saakashvili government claims about his opponents, our political orientation is not pro-Russian, but pro-Georgian.\n",
        "Target: Вне зависимости от того, что правительство Саакашвили говорит о своих оппонентах, наша политическая ориентация не пророссийская, а прогрузинская.\n",
        "Predicted: Независимо от того , что правительство Саакашвили заявляет о своих оппонентов , наша политическая ориентация не является , а .\n",
        "Processing epoch 06: 100%|██████████| 5347/5347 [1:05:43<00:00,  1.36it/s, loss=2.837]\n",
        "--------------------------------------------------------------------------------\n",
        "Source: The IIF believes that GDP could be fully 5% lower after five years, with unemployment more than 7% higher.\n",
        "Target: ИМФ считает, что ВВП после пяти лет может сократиться на целые 5%, а безработица может оказаться на 7% выше.\n",
        "Predicted: полагает , что ВВП может быть в целых 5 % ниже , чем на пять лет , а безработица выше на 7 %.\n",
        "--------------------------------------------------------------------------------\n",
        "Source: Indeed, China is on the precipice of becoming an environmental wasteland.\n",
        "Target: Действительно, Китай находится на гране превращения в экологическую свалку.\n",
        "Predicted: Действительно , Китай находится на краю пропасти , став экологические .\n",
        "Processing epoch 07: 100%|██████████| 5347/5347 [1:05:41<00:00,  1.36it/s, loss=2.593]\n",
        "--------------------------------------------------------------------------------\n",
        "Source: The opposition must build itself as a credible and attractive alternative to the Assad regime, and the regime’s international and regional critics must assist in that process.\n",
        "Target: Оппозиция должна проявить себя как надежная и привлекательная альтернатива режиму Асада, а международные и региональные критики режима должны помогать в этом процессе.\n",
        "Predicted: Оппозиция должна построить себе как , так и привлекательную альтернативу режиму Асада , и международные и региональные критики должны помочь в этом процессе .\n",
        "--------------------------------------------------------------------------------\n",
        "Source: Lastly, don't take too dogmatic a view of corruption and or the looting of the public coffers; they are part of the system.\n",
        "Target: И, наконец – не судите слишком строго коррупцию и грабеж общественной казны – это часть системы.\n",
        "Predicted: И , наконец , не следует слишком взгляд на коррупцию и государственной ; они являются частью системы .\n",
        "Processing epoch 08: 100%|██████████| 5347/5347 [1:05:45<00:00,  1.36it/s, loss=2.637]\n",
        "--------------------------------------------------------------------------------\n",
        "Source: After all, while his policy of confrontation has generated high levels of violence, tolerance of the drug cartels corrupted state institutions, sowing the ground for the problem in the first place.\n",
        "Target: В конце концов, в то время как его политика конфронтации привела к высокому уровню насилия, толерантность к наркокартелям привела к коррупции государственных учреждений, изначально создавая основу для проблем.\n",
        "Predicted: В конце концов , в то время как его политика конфронтации привела к высокому уровню насилия , терпимость к государственных институтов , почву для проблемы в первом месте .\n",
        "--------------------------------------------------------------------------------\n",
        "Source: If you spin the bottle and create an eddy inside it, the water will flow out much faster and more smoothly.\n",
        "Target: Если Вы будете вращать бутылку и создадите внутри нее воронку, вода вытечет намного быстрее и ровным потоком.\n",
        "Predicted: Если вы и в ней , вода гораздо быстрее и гладко .\n",
        "Processing epoch 09: 100%|██████████| 5347/5347 [1:05:41<00:00,  1.36it/s, loss=2.522]\n",
        "--------------------------------------------------------------------------------\n",
        "Source: On April 29, 1865, this radical proposal scraped through the Massachusetts General Court (the state’s bi-cameral legislature), owing to intense lobbying and the goodwill generated by Harvard alumni’s distinguished service for the Union during the Civil War.\n",
        "Target: 29 апреля 1865 года это радикальное предложение прошло через Главный суд штата Массачусетс (двухпалатный законодательный орган штата), вследствие интенсивного лоббирования и доброй воли, которые обеспечили заслуги выпускников Гарварда перед Союзом во времена Гражданской войны.\n",
        "Predicted: 29 апреля , , данное радикальное предложение судом ( - законодательство государства ), вызванное интенсивным и , в для Союза во время гражданской войны .\n",
        "--------------------------------------------------------------------------------\n",
        "Source: So long as a large number of American troops remains as an occupying force, they serve as a recruiting tool for insurgents.\n",
        "Target: До тех пор пока большое количество американских войск находится в стране в качестве оккупационной силы, они являются идеальным орудием вербовки для мятежников.\n",
        "Predicted: До тех пор , пока большое количество американских войск остается оккупационной силой , они служат инструментом для повстанцев ."
      ],
      "metadata": {
        "id": "lmGWw0l41WNb"
      },
      "id": "lmGWw0l41WNb"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwjRs9nsAVip"
      },
      "id": "DwjRs9nsAVip",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da17a031275945c5a8f7a0bc23b756c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f0feeaa5d3e45b3a1edd76a2e719f84",
              "IPY_MODEL_78b70917e22d4db7b47e42c649931c44",
              "IPY_MODEL_e8a7ea0236574c9795ce7f8fc4f78537"
            ],
            "layout": "IPY_MODEL_45bb98d4de944d8e9ee8d65a6ce41f16"
          }
        },
        "2f0feeaa5d3e45b3a1edd76a2e719f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c307381abc44f56823c844f8892c61d",
            "placeholder": "​",
            "style": "IPY_MODEL_c92815058b914c858fe3f39fa81f88a3",
            "value": "README.md: 100%"
          }
        },
        "78b70917e22d4db7b47e42c649931c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4e2eec0848a4b79a59caef658355632",
            "max": 26883,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf027fb932fa406bac66af3dc43edf5d",
            "value": 26883
          }
        },
        "e8a7ea0236574c9795ce7f8fc4f78537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3acd089fe6e741638a19915c131af406",
            "placeholder": "​",
            "style": "IPY_MODEL_8fe350be9e8e4c66b038e98fc19014ca",
            "value": " 26.9k/26.9k [00:00&lt;00:00, 2.99MB/s]"
          }
        },
        "45bb98d4de944d8e9ee8d65a6ce41f16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c307381abc44f56823c844f8892c61d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c92815058b914c858fe3f39fa81f88a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4e2eec0848a4b79a59caef658355632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf027fb932fa406bac66af3dc43edf5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3acd089fe6e741638a19915c131af406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fe350be9e8e4c66b038e98fc19014ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57302ed877d7443395a8b5e21021e0b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04ba5114bec441d0a0955ad0bc508193",
              "IPY_MODEL_e3f8a250e4334ddc95964b96019c9909",
              "IPY_MODEL_0ebd3cdc1ebf4a80af80719f5e042cc8"
            ],
            "layout": "IPY_MODEL_5a4cb79c9a4f4997a319dbea515341c3"
          }
        },
        "04ba5114bec441d0a0955ad0bc508193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b50bed43e23749cc8f212061499f837b",
            "placeholder": "​",
            "style": "IPY_MODEL_565afc75ddcc4541b1fb43446e73bafc",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "e3f8a250e4334ddc95964b96019c9909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b78f9cefd6f2421aa1a63918b6e0206e",
            "max": 45349681,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbf1313ad4054ea3be7628fef9a1b99f",
            "value": 45349681
          }
        },
        "0ebd3cdc1ebf4a80af80719f5e042cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0b4952a794e479caddd7c3d183dcb50",
            "placeholder": "​",
            "style": "IPY_MODEL_225d4f70c2f14f598e160eba0fb1b1a5",
            "value": " 45.3M/45.3M [00:00&lt;00:00, 144MB/s]"
          }
        },
        "5a4cb79c9a4f4997a319dbea515341c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b50bed43e23749cc8f212061499f837b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "565afc75ddcc4541b1fb43446e73bafc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b78f9cefd6f2421aa1a63918b6e0206e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbf1313ad4054ea3be7628fef9a1b99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0b4952a794e479caddd7c3d183dcb50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "225d4f70c2f14f598e160eba0fb1b1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13436155f4e0445587ab0957a71b1448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_553800040db04888bd7f05476c797c8a",
              "IPY_MODEL_85af20ef3dd44267a975810041d83a40",
              "IPY_MODEL_aa9e3ee3fe3b486ea56db4c38678ea17"
            ],
            "layout": "IPY_MODEL_ee620753b17b4b00a35d63a5f8557943"
          }
        },
        "553800040db04888bd7f05476c797c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fc4c9939ef34ece98b930b20c796732",
            "placeholder": "​",
            "style": "IPY_MODEL_f4c450081c964b6f9d46daaa075bc7f6",
            "value": "Generating train split: 100%"
          }
        },
        "85af20ef3dd44267a975810041d83a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec19e03613f84da1ad1c9bde3105f9db",
            "max": 190104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_457302a4607e49a59a1661f32693b363",
            "value": 190104
          }
        },
        "aa9e3ee3fe3b486ea56db4c38678ea17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0adc10605a0472c838a92486851a928",
            "placeholder": "​",
            "style": "IPY_MODEL_6c879bd9644e4991ac7a8e809f043630",
            "value": " 190104/190104 [00:00&lt;00:00, 501628.30 examples/s]"
          }
        },
        "ee620753b17b4b00a35d63a5f8557943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc4c9939ef34ece98b930b20c796732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4c450081c964b6f9d46daaa075bc7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec19e03613f84da1ad1c9bde3105f9db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "457302a4607e49a59a1661f32693b363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0adc10605a0472c838a92486851a928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c879bd9644e4991ac7a8e809f043630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}